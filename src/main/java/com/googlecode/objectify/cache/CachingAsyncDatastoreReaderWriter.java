package com.googlecode.objectify.cache;

import com.google.cloud.datastore.AggregationQuery;
import com.google.cloud.datastore.AggregationResults;
import com.google.cloud.datastore.FullEntity;
import com.google.cloud.datastore.Key;
import com.google.cloud.datastore.Query;
import com.google.cloud.datastore.QueryResults;
import com.google.cloud.datastore.ReadOption;
import com.google.cloud.datastore.models.ExplainOptions;
import com.googlecode.objectify.impl.AsyncDatastoreReaderWriter;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;

import java.util.ArrayList;
import java.util.List;
import java.util.concurrent.Future;

/**
 * <p>A write-through memcache for Entity objects that works for both transactional
 * and nontransactional sessions.</p>
 * 
 * <ul>
 * <li>Caches negative results as well as positive results.</li>
 * <li>Queries do not affect the cache in any way.</li>
 * <li>Transactional reads bypass the cache, but successful transaction commits will update the cache.</li>
 * <li>This cache has near-transactional integrity.  As long as DeadlineExceededException is not hit, cache should
 * not go out of sync even under heavy contention.</li>
 * </ul>
 * 
 * <p>Note:  Until Google adds a hook that lets us wrap native Future<?> implementations,
 * you muse install the {@code AsyncCacheFilter} to use this cache asynchronously.  This
 * is not necessary for synchronous use of {@code CachingDatastoreService}, but asynchronous
 * operation requires an extra hook for the end of a request when fired-and-forgotten put()s
 * and delete()s get processed.  <strong>If you use this cache asynchronously, and you do not
 * use the {@code AsyncCacheFilter}, your cache will go out of sync.</strong></p>
 * 
 * @author Jeff Schnitzer <jeff@infohazard.org>
 */
@RequiredArgsConstructor
@Slf4j
abstract public class CachingAsyncDatastoreReaderWriter implements AsyncDatastoreReaderWriter
{
	/** */
	private final AsyncDatastoreReaderWriter raw;
	
	abstract protected void empty(Iterable<Key> keys);

	@Override
	public Future<Void> delete(final Iterable<Key> keys) {
		// Always trigger, even on failure - the delete might have succeeded even though a timeout
		// exception was thrown.  We will always be safe emptying the key from the cache.
		return new TriggerFuture<Void>(this.raw.delete(keys)) {
			@Override
			protected void trigger() {
				empty(keys);
			}
		};
	}

	@Override
	public <T> QueryResults<T> run(final Query<T> query) {
		return this.raw.run(query);
	}

	@Override
	public <T> QueryResults<T> run(final Query<T> query, final ExplainOptions explainOptions, final ReadOption... options) {
		return this.raw.run(query, explainOptions, options);
	}

	@Override
	public Future<List<Key>> put(final Iterable<? extends FullEntity<?>> entities) {
		// There is one weird case we have to watch out for.  When you put() entities without
		// a key, the backend autogenerates the key for you.  But the put() might throw an
		// exception (eg timeout) even though it succeeded in the backend.  Thus we wrote
		// an entity in the datastore but we don't know what the key was, so we can't empty
		// out any negative cache entry that might exist.

		// The solution to this is that we need to allocate ids ourself before put()ing the entity.
		// Unfortunately there is no Entity.setKey() method or Key.setId() method, so we can't do this
		// The best we can do is watch out for when there is a potential problem and warn the
		// developer in the logs.

		final List<Key> inputKeys = new ArrayList<>();
		boolean foundAutoGenKeys = false;

		for (final FullEntity<?> ent: entities)
			if (ent.getKey() instanceof Key)	// is complete
				inputKeys.add((Key)ent.getKey());
			else
				foundAutoGenKeys = true;

		final boolean hasAutoGenKeys = foundAutoGenKeys;

		// Always trigger, even on failure - the delete might have succeeded even though a timeout
		// exception was thrown.  We will always be safe emptying the key from the cache.
		final Future<List<Key>> future = new TriggerFuture<List<Key>>(this.raw.put(entities)) {
			@Override
			protected void trigger() {
				// This is complicated by the fact that some entities may have been put() without keys,
				// so they will have been autogenerated in the backend.  If a timeout error is thrown,
				// it's possible the commit succeeded but we won't know what the key was.  If there was
				// already a negative cache entry for this, we have no way of knowing to clear it.
				// This must be pretty rare:  A timeout on a autogenerated key when there was already a
				// negative cache entry.  We can detect when this is a potential case and log a warning.
				// The only real solution to this is to allocate ids in advance.  Which maybe we should do.

				List<Key> keys;
				try {
					keys = this.raw.get();
				} catch (Exception ex) {
					keys = inputKeys;

					if (hasAutoGenKeys)
						log.warn("A put() for an Entity with an autogenerated key threw an exception. Because the write" +
								" might have succeeded and there might be a negative cache entry for the (generated) id, there" +
								" is a small potential for cache to be incorrect.");
				}

				empty(keys);
			}
		};

		return future;
	}

	@Override
	public Future<AggregationResults> runAggregation(final AggregationQuery query) {
		return this.raw.runAggregation(query);
	}
}


